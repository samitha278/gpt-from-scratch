{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj0SYIVEZmegLKPzBmMbPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitha278/gpt-from-scratch/blob/main/GPT_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import random"
      ],
      "metadata": {
        "id": "tDPI-mQIHtht"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1ia6z4itw7WJWpnoTohURX6Lm-AnZmVZz\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "output = \"input.txt\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "vX2lDjnvIvll",
        "outputId": "80cb9828-ce94-46fc-dee6-e73e525545cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ia6z4itw7WJWpnoTohURX6Lm-AnZmVZz\n",
            "To: /content/input.txt\n",
            "100%|██████████| 1.12M/1.12M [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nv2qQxTJYH0",
        "outputId": "2d57dfc6-645b-4bff-e4e8-fe3fd4a0e941"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw2xR7QTKFvp",
        "outputId": "7b5cb271-a673-466d-e4fe-70582d7f5680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {s:i for i,s in enumerate(chars)}\n",
        "itos = {i:s for i,s in enumerate(chars)}\n",
        "\n",
        "encode = lambda s : [stoi[ch] for ch in s]\n",
        "decode = lambda l : ''.join(itos[i] for i in l)\n",
        "\n",
        "print(encode(\"Hello world\"))\n",
        "print(decode(encode(\"Hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnqtaA5KG4X",
        "outputId": "b9dbf102-ecd6-4c77-ef04-fd652c3228d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
            "Hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text))\n",
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjyancDSRgIp",
        "outputId": "fa286448-e328-4688-8420-20f7d5baccd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
              "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
              "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
              "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
              "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9* len(data))\n",
        "train = data[:n]\n",
        "val = data[n:]"
      ],
      "metadata": {
        "id": "gCCeKh6WUFYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "\n",
        "x = train[:block_size]\n",
        "y = train[1:block_size+1]\n",
        "\n",
        "for i in range(block_size):\n",
        "  context = x[:i+1]\n",
        "  target = y[i]\n",
        "\n",
        "  print(f'{context} target:{target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F1f9l90VVvC",
        "outputId": "8dbef70d-1cdb-44de-be59-94768ca57b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18]) target:47\n",
            "tensor([18, 47]) target:56\n",
            "tensor([18, 47, 56]) target:57\n",
            "tensor([18, 47, 56, 57]) target:58\n",
            "tensor([18, 47, 56, 57, 58]) target:1\n",
            "tensor([18, 47, 56, 57, 58,  1]) target:15\n",
            "tensor([18, 47, 56, 57, 58,  1, 15]) target:47\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47]) target:58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(100-block_size, (4,))\n",
        "ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0dSQLVFM4UQ",
        "outputId": "a0b2b4bb-78e7-4d09-ea9e-a4f7a85fb27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([57, 75, 26, 74])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(278)\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "\n",
        "def get_batch(split):\n",
        "\n",
        "  data = train if split=='train' else val\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:block_size+i] for i in ix])\n",
        "  y = torch.stack([data[i+1:block_size+i+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "\n",
        "xb,yb = get_batch('train')\n",
        "\n",
        "xb,yb"
      ],
      "metadata": {
        "id": "VUqDG0uBcN0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd43db8-80af-448a-8078-037b3ee0bf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[47, 57,  0, 42, 39, 59, 45, 46],\n",
              "         [40, 59, 58,  1, 40, 39, 57, 58],\n",
              "         [58, 53,  1, 46, 43, 56,  1, 57],\n",
              "         [50, 63,  0, 58, 39, 56, 56, 63]]),\n",
              " tensor([[57,  0, 42, 39, 59, 45, 46, 58],\n",
              "         [59, 58,  1, 40, 39, 57, 58, 39],\n",
              "         [53,  1, 46, 43, 56,  1, 57, 53],\n",
              "         [63,  0, 58, 39, 56, 56, 63,  1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram Language Model"
      ],
      "metadata": {
        "id": "-bdswUyciIta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(278)\n",
        "\n",
        "class BigramLM(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.token_emb_table = nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "\n",
        "  def __call__(self,idx , targets=None):\n",
        "\n",
        "    logits = self.token_emb_table(idx)    #shape: (b,t,c)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      loss = F.cross_entropy(logits.view(-1,vocab_size) , targets.view(-1))\n",
        "\n",
        "    return logits , loss\n",
        "\n",
        "\n",
        "  def generate(self,idx, max_new_tokens):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "      logits , loss = self(idx)\n",
        "\n",
        "      logits = logits[:,-1,:] #from all batch's last element's logits\n",
        "\n",
        "      probs = F.softmax(logits,dim=1)\n",
        "\n",
        "      ix = torch.multinomial(probs,num_samples=1)\n",
        "\n",
        "      idx = torch.cat((idx,ix), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "\n",
        "bigram = BigramLM(vocab_size)\n",
        "logits , loss = bigram(xb,yb)\n",
        "\n",
        "print(logits.shape,loss)\n",
        "\n",
        "\n",
        "\n",
        "idx= torch.zeros((1,1),dtype= torch.long)\n",
        "\n",
        "print(decode(bigram.generate(idx,max_new_tokens=100)[0].tolist()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcc2HxMHv5l",
        "outputId": "9f9c4017-cfe0-49ee-a596-d1bf0e55a087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 65]) tensor(4.5468, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "hDkMQcyOQpP-rU-,VfVk:rXwxj Ug$$kNRxr.x'R3ULl!WC?fErPF'K'nybrlziq:IF:J.-YVN.jj$R-kDwR\n",
            "hWiDAg,rHH'!JzL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([i.shape for i in bigram.parameters()])   #token_emb_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok6jBOBXMMAK",
        "outputId": "51261983-430f-4bb9-a6f9-7907c3d33a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.Size([65, 65])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(bigram.parameters(),lr = 1e-3)"
      ],
      "metadata": {
        "id": "O-8ftb_0kxxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "  xb,yb = get_batch('train')\n",
        "\n",
        "  logits , loss = bigram(xb,yb  )\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%10000 == 0:\n",
        "    print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z18XvwxBqk7J",
        "outputId": "157bf27e-723c-4674-a909-d4d01a3f6e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.7092204093933105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx= torch.zeros((1,1),dtype= torch.long)\n",
        "\n",
        "print(decode(bigram.generate(idx,max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCpboy-Osf_q",
        "outputId": "f7dbb759-1645-4997-e9a3-4e3b6467a374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "hW. U EQ&KHb\n",
            "SKB3FKB&jq&p;JoYXMvlik:cusuILA:ivFrod3Y!\n",
            "K?$ne FsT liO't JCoAHpEqKLKm!mLD3fMWArtawnJICl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging past context"
      ],
      "metadata": {
        "id": "szy4_fxo83D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = get_batch('train')\n",
        "x[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie_2vD6R8hWy",
        "outputId": "00635249-e57d-452c-abb0-22d5b6434b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[49,  1, 46, 47, 57,  1, 45, 56],\n",
              "        [ 1, 50, 47, 60, 43,  6,  0, 21],\n",
              "        [61, 56, 39, 54,  1, 53, 59, 56],\n",
              "        [46,  7,  7,  0,  0, 29, 33, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = bigram(x,y)\n",
        "B,T,C = xb.shape\n",
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McqmuoSMs8KP",
        "outputId": "154c46bc-c85b-475a-8221-40af5ca485d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros(xb.shape)\n",
        "\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "\n",
        "    xprev = xb[b,:t+1]\n",
        "    xbow[b,t] = xprev.mean(0)"
      ],
      "metadata": {
        "id": "EvqNBUVY8_8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging with matrix multiplication"
      ],
      "metadata": {
        "id": "9zE5JLMNJZQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg8 = torch.tensor([1/i for i in range(1,T+1)])\n",
        "avg8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc4zw8RI98ts",
        "outputId": "784ffd5b-e40f-49d2-ed3f-406a745e99fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 0.5000, 0.3333, 0.2500, 0.2000, 0.1667, 0.1429, 0.1250])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg88 = (avg8*torch.ones(T,T)).T"
      ],
      "metadata": {
        "id": "PyD4iqGcG1X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg88_tril = torch.tril(avg88)\n",
        "avg88_tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym0kyf3_I9E-",
        "outputId": "c5f6350f-2d26-46eb-f5ce-183078c95398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(T,T))\n",
        "a = a / a.sum(1,keepdim=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwvxD1pXLBl3",
        "outputId": "18139f5b-f119-4d54-cae6-1598925b8746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow_mat = torch.zeros(xb.shape)\n",
        "\n",
        "for batch in range(B):\n",
        "  xbow_mat[batch] = a @ xb[batch]\n"
      ],
      "metadata": {
        "id": "EZ9CAWEwJJrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2 = a @ xb"
      ],
      "metadata": {
        "id": "oLQwX-QFMVSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow,xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkkmgcC3KYPL",
        "outputId": "798ff183-2fb1-4d39-8473-62091ef5bac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary of averaging"
      ],
      "metadata": {
        "id": "lhh4vygKNBV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(T,T))\n",
        "a = a / a.sum(1,keepdim=True)\n",
        "\n",
        "xbow = a @ xb\n"
      ],
      "metadata": {
        "id": "R7-Q7Pe6M1g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 3"
      ],
      "metadata": {
        "id": "tyz-62DQRov_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "\n",
        "wei = F.softmax(wei,dim = 1)\n",
        "\n",
        "xbow3 = wei @ xb\n",
        "(xbow3 == xbow2).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Z9p3OuRoWM",
        "outputId": "0623aa22-5f74-4143-c50c-cc40eebbc35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 4 - Self attention"
      ],
      "metadata": {
        "id": "Wo7yxXGNun3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(278)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "\n",
        "head_size = 16\n",
        "\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "id": "opdWkZ9qsDqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ea46c2-b463-40bd-8e76-9fefe14cc57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mat mul high dimension"
      ],
      "metadata": {
        "id": "R0NiIdN7sSHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((2,4,8))\n",
        "b = torch.randn((2,4,4))\n",
        "b @ a"
      ],
      "metadata": {
        "id": "JRyGfr0qKbvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43346183-ed20-4de7-8cbd-45b5467da43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1080,  3.4493, -0.0389, -2.0157,  0.3596, -1.5135,  1.6457,\n",
              "          -1.3712],\n",
              "         [-1.0791, -0.5694, -0.1386,  2.9522,  0.5635,  0.4879, -1.8812,\n",
              "           3.2153],\n",
              "         [-1.7204, -0.5798,  0.2062,  0.4670,  0.4478, -0.1849, -0.1060,\n",
              "           1.6224],\n",
              "         [-2.2160,  4.4720,  0.0718, -1.4928,  1.2393, -2.3581,  1.6715,\n",
              "           0.7310]],\n",
              "\n",
              "        [[ 3.7422, -0.6046,  1.8760, -1.7515,  1.8201, -2.3911, -2.3626,\n",
              "           0.6900],\n",
              "         [ 3.2248,  0.7812,  2.1391, -0.6751,  1.5220, -2.4509, -3.0965,\n",
              "           1.6815],\n",
              "         [ 3.8133, -1.2514,  2.2410, -2.2957,  2.3149, -2.5146, -0.9141,\n",
              "           0.3985],\n",
              "         [ 2.1424, -1.9206,  4.1068, -1.7650,  2.1677, -1.9662,  5.3301,\n",
              "           0.0766]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xt,yt = get_batch('train')\n",
        "\n",
        "xt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAvm6jslBQR9",
        "outputId": "163f1df4-55a9-4ff0-adca-79aed4e54386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embd = nn.Embedding(65,40)\n",
        "token_embd.weight.shape\n",
        "\n",
        "out = token_embd(xt)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0u7GD7pC5Uh",
        "outputId": "7ca4140c-afd4-4896-e7fa-b944e33c8910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm_head = nn.Linear(40,65)\n",
        "lm_head.weight.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9x51LPjDFAi",
        "outputId": "b0f8a440-d288-42d0-b579-1c823b6f311c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm_head(out).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azupvkEMLg_l",
        "outputId": "1ce9ab6c-305f-46a7-e7a7-147893f6bbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 Updated Bigram\n"
      ],
      "metadata": {
        "id": "iLwjnX8uz5GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 32\n",
        "block_size = 64\n",
        "eval_iters = 10000\n",
        "n_embd = 128\n",
        "head_size = n_embd\n",
        "max_iter  = 10000\n",
        "learning_rate = 1e-2"
      ],
      "metadata": {
        "id": "6E-l_4D0-yQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class selfAttentionHead(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        B,T,C = x.shape\n",
        "\n",
        "        key = self.key(x)\n",
        "        query = self.query(x)\n",
        "\n",
        "        weight = query @ key.transpose(-2,-1) * C**-0.5\n",
        "        weight = weight.masked_fill(self.tril[:T,:T]==0,float('-inf'))\n",
        "        weight = F.softmax(weight,dim=-1)\n",
        "\n",
        "        value = self.value(x)\n",
        "\n",
        "        self.out = weight @ value\n",
        "\n",
        "        return self.out\n",
        "\n",
        "\n",
        "\n",
        "class transformerDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embd_table = nn.Embedding(vocab_size,n_embd)\n",
        "        self.pos_embd_table = nn.Embedding(block_size,n_embd)\n",
        "\n",
        "        self.sa_head = selfAttentionHead(head_size)\n",
        "\n",
        "        self.lm_head = nn.Linear(head_size,vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,input, targets = None):\n",
        "\n",
        "        B,T = input.shape\n",
        "\n",
        "        token_embd = self.embd_table(input)\n",
        "        pos_embd = self.pos_embd_table(torch.arange(T))\n",
        "\n",
        "        x = token_embd+pos_embd\n",
        "        x = self.sa_head(x)\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B,T,C = logits.shape\n",
        "            loss = F.cross_entropy(logits.view(B*T,C),targets.view(-1))\n",
        "\n",
        "        return logits , loss\n",
        "\n",
        "\n",
        "\n",
        "    def generate(self,input,max_token):\n",
        "\n",
        "        for _ in range(max_token):\n",
        "            input_cond = input[:,-block_size:]\n",
        "            logits , loss = self(input_cond)\n",
        "            logits = logits[:,-1,:]\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_index = torch.multinomial(probs,1)\n",
        "\n",
        "            input = torch.cat((input,next_index),dim = 1)\n",
        "\n",
        "        return input\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        # create a PyTorch optimizer\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for i in range(max_iter):\n",
        "\n",
        "            xb,yb = get_batch('train')\n",
        "\n",
        "            # evaluate model\n",
        "            logits , loss = model(xb,yb)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            if i% (max_iter/10) == 0:\n",
        "                print(f'{i}/{max_iter}  {loss}')\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "# model evaluation\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train model\n",
        "model = transformerDecoder()\n",
        "#model.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# genarate from the model\n",
        "# context = torch.zeros((1,1),dtype=torch.long)\n",
        "# print(decode(model.generate(context,max_token=100)[0].tolist()))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "84zZf-riL2hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.__dict__['_modules']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc0vZGwB1awT",
        "outputId": "e19d2c35-251a-4c38-e45a-00994f2872eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'embd_table': Embedding(65, 128),\n",
              " 'pos_embd_table': Embedding(8, 128),\n",
              " 'sa_head': selfAttentionHead(\n",
              "   (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "   (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "   (value): Linear(in_features=128, out_features=16, bias=False)\n",
              " ),\n",
              " 'lm_head': Linear(in_features=16, out_features=65, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "68aLDCPB7Uso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "block_size = 8\n",
        "eval_iters = 10000\n",
        "n_embd = 128\n",
        "head_size = 16\n",
        "max_iter  = 10000\n",
        "learning_rate = 1e-2"
      ],
      "metadata": {
        "id": "EK7U7K-E6ZYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input= torch.tensor([[53, 50, 43, 56, 10,  0, 25, 39]])\n",
        "targets = torch.tensor([50, 43, 56, 10,  0, 25, 39, 42])"
      ],
      "metadata": {
        "id": "9-7YWLPK7kko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model = transformerDecoder()"
      ],
      "metadata": {
        "id": "asRPHFFr9-xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model(input,targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q6u341X-dCn",
        "outputId": "5e8d8995-2449-4650-8a94-229c14f1cc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 3.3355e-01,  6.8891e-01, -8.3918e-01,  1.0558e+00, -6.4635e-01,\n",
              "            7.8033e-01,  5.4743e-01,  1.2486e-01, -6.3534e-02,  1.5087e-01,\n",
              "            5.5966e-01, -7.2753e-02, -1.9249e-01,  1.4256e-01, -4.9183e-03,\n",
              "           -6.4516e-01,  9.2371e-02, -5.7139e-01, -7.9722e-01, -2.4662e-01,\n",
              "           -4.1347e-01,  3.2933e-01,  7.5681e-01, -6.5150e-01, -1.5127e-01,\n",
              "            3.0669e-01, -2.5543e-01, -4.1121e-01, -1.9136e-01, -2.4008e-01,\n",
              "            8.5032e-02, -3.7000e-01,  3.8740e-01,  1.0096e-02, -1.9931e-01,\n",
              "           -1.3735e-02, -1.0452e-01, -2.8312e-01, -3.9280e-01,  4.1761e-01,\n",
              "           -1.1185e-01, -9.2053e-01,  3.0232e-01,  2.2996e-01,  1.1474e-01,\n",
              "            7.1255e-01, -3.1004e-01, -2.5723e-01,  5.8349e-02, -3.9239e-01,\n",
              "            1.0397e+00, -4.0278e-01,  8.5969e-01,  7.7121e-01, -6.2261e-01,\n",
              "           -8.6065e-01, -4.7702e-01, -1.0585e-01,  8.5334e-02, -7.1318e-01,\n",
              "            6.1245e-02, -1.5040e-01,  4.3655e-01, -6.4171e-01,  3.8137e-03],\n",
              "          [ 9.2931e-02,  4.4460e-01, -1.8489e-01,  6.5227e-01, -3.1574e-01,\n",
              "            3.4559e-01,  4.4996e-01, -5.8501e-02, -3.5738e-01,  1.1491e-01,\n",
              "            2.8621e-01, -7.4732e-02, -1.1158e-01, -9.4630e-02, -7.5898e-02,\n",
              "           -3.7868e-01,  1.4198e-01, -2.2599e-01, -3.8791e-01, -1.5120e-01,\n",
              "           -9.1859e-02,  2.0165e-01,  3.8438e-01, -2.1456e-01, -8.1624e-02,\n",
              "            3.3883e-01,  7.4228e-02, -1.9677e-01,  4.8797e-02, -3.7124e-01,\n",
              "           -9.1955e-02, -8.5763e-02,  2.1947e-01,  1.6729e-01, -2.2840e-01,\n",
              "           -1.3241e-01, -1.9607e-01, -1.5283e-01, -2.7442e-01,  1.0548e-01,\n",
              "           -1.0667e-01, -6.4323e-01,  1.6857e-01,  3.1528e-01,  1.3451e-01,\n",
              "            3.0369e-01, -1.0636e-01,  4.1723e-03,  1.8605e-01, -2.1317e-01,\n",
              "            5.9113e-01, -1.3311e-01,  5.4991e-01,  3.9431e-01, -5.7563e-01,\n",
              "           -3.4061e-01, -5.9249e-01, -1.6357e-01, -1.4844e-02, -3.0234e-01,\n",
              "           -8.2649e-02,  1.7593e-03,  1.8595e-01, -3.7524e-01, -6.5713e-03],\n",
              "          [ 5.8140e-02,  1.4013e-01, -1.7634e-01,  5.6619e-01,  8.1702e-02,\n",
              "            4.8947e-02,  2.4310e-01, -4.8139e-01, -3.4624e-01,  1.8550e-01,\n",
              "            2.2565e-01, -1.5039e-01, -2.5703e-01, -1.6945e-01,  1.3153e-01,\n",
              "           -5.8338e-02,  2.9212e-01,  9.1834e-02,  2.4068e-02,  5.9858e-02,\n",
              "           -4.4152e-01, -3.5242e-02, -2.3211e-02, -2.7893e-01, -2.0675e-01,\n",
              "            3.0955e-01, -2.2540e-01,  3.0053e-01, -1.1401e-01, -7.7621e-02,\n",
              "            4.3097e-02,  3.0933e-01,  1.2195e-01, -6.2154e-02, -3.0636e-01,\n",
              "            8.1561e-02, -5.6756e-01, -1.3610e-01, -1.9108e-01,  8.8957e-02,\n",
              "           -4.6231e-01, -5.0774e-01,  6.2143e-02,  3.1967e-01, -1.6205e-01,\n",
              "            1.7331e-01, -6.2891e-02,  1.5802e-01,  9.2044e-02,  9.0847e-03,\n",
              "            3.7193e-01, -2.6598e-02,  7.4156e-01,  1.1962e-01, -3.1929e-01,\n",
              "           -1.4190e-01, -7.7921e-01, -2.8166e-01, -1.9967e-01, -2.1671e-01,\n",
              "           -1.2104e-01,  5.0391e-03,  2.5922e-01, -4.1432e-01,  2.3439e-01],\n",
              "          [ 2.3599e-01, -8.0182e-02, -1.2441e-02,  4.3550e-01,  3.6337e-01,\n",
              "           -9.8168e-02,  2.9004e-01, -5.9183e-01, -4.9962e-01,  1.1020e-01,\n",
              "           -3.8103e-02, -1.7227e-01, -4.9699e-01, -2.0461e-01,  1.6460e-01,\n",
              "            7.5740e-02,  1.4785e-01,  4.6079e-02,  9.2760e-02,  6.4661e-02,\n",
              "           -2.3275e-01, -1.6126e-01, -4.5251e-02, -7.5905e-02,  5.3822e-02,\n",
              "            3.5446e-01, -3.2876e-01,  7.5405e-02, -1.5711e-01,  6.0903e-02,\n",
              "           -2.8767e-01,  3.5736e-01,  1.7749e-01,  2.6342e-02, -4.4277e-01,\n",
              "            1.6027e-01, -6.6656e-01, -1.8706e-01, -2.2444e-01, -2.2366e-01,\n",
              "           -3.6518e-01, -3.7291e-01,  1.4887e-03,  1.7488e-01, -1.8477e-01,\n",
              "           -1.5961e-02, -7.6810e-03,  3.8320e-01,  1.9125e-01, -1.0242e-01,\n",
              "            1.7937e-01, -3.8147e-02,  4.9249e-01,  1.5436e-01, -3.2106e-01,\n",
              "           -3.6954e-02, -5.4865e-01, -3.1036e-01, -2.1275e-01, -1.2152e-01,\n",
              "           -2.9018e-01,  2.2377e-01, -1.3439e-01, -3.7514e-01,  2.2222e-01],\n",
              "          [ 7.0017e-02,  1.9236e-01, -2.4325e-01,  4.0691e-01, -1.6312e-02,\n",
              "            1.8418e-01,  4.2030e-01, -9.7469e-02, -4.4694e-01,  4.2990e-03,\n",
              "            1.6216e-01, -2.0785e-01, -3.7577e-01, -1.3930e-01, -9.7453e-02,\n",
              "           -8.2241e-03, -2.6809e-02, -6.6894e-02, -1.4919e-01, -1.3223e-01,\n",
              "           -4.3624e-02,  3.3835e-02,  9.2653e-02, -2.4416e-01, -4.6819e-02,\n",
              "            1.9881e-01, -3.1221e-02, -7.4125e-02, -2.8427e-04, -1.1731e-01,\n",
              "           -3.3893e-01,  5.5141e-03,  9.4174e-02, -7.2580e-02, -3.7284e-01,\n",
              "           -4.6853e-02, -4.0026e-01, -5.4227e-02, -2.1427e-01, -8.8896e-02,\n",
              "           -1.5371e-01, -5.4827e-01, -2.9954e-02,  1.2330e-01,  3.8086e-02,\n",
              "            1.2098e-01, -1.8522e-01,  1.4699e-01,  2.1194e-01, -2.4753e-01,\n",
              "            2.5616e-01, -3.5782e-02,  5.3338e-01,  2.5420e-01, -2.9470e-01,\n",
              "           -2.4196e-01, -4.5156e-01, -3.3032e-01, -2.9293e-01, -4.6303e-01,\n",
              "           -1.5025e-01,  7.0582e-02,  1.1273e-02, -4.0243e-01,  5.4481e-02],\n",
              "          [ 1.4243e-01,  1.0630e-01, -3.7976e-01,  4.4360e-01, -1.8392e-01,\n",
              "            2.4462e-01,  3.3597e-01, -7.6749e-02, -3.5056e-01,  2.0804e-03,\n",
              "            2.9653e-01, -2.6992e-01, -4.0587e-01, -9.4924e-02,  2.8137e-02,\n",
              "           -2.6981e-02, -7.1496e-02,  6.7813e-02, -8.7205e-02, -1.7715e-01,\n",
              "           -3.1192e-01, -5.5737e-02,  3.2929e-02, -3.8049e-01, -2.7100e-02,\n",
              "            1.2708e-01, -2.0398e-01,  4.0125e-02,  1.3830e-01, -1.8411e-02,\n",
              "           -1.2432e-01,  2.1290e-01,  1.0429e-01, -9.0828e-02, -3.2693e-01,\n",
              "            8.5548e-02, -5.0872e-01,  1.5485e-01, -5.9551e-02,  4.2038e-02,\n",
              "           -1.3674e-02, -4.5294e-01, -8.0077e-04,  1.9278e-01, -4.7782e-02,\n",
              "            1.6026e-01, -2.8258e-01,  1.4812e-01,  2.3905e-01, -1.9482e-01,\n",
              "            1.2741e-01, -1.1335e-01,  5.4271e-01,  2.0456e-01, -1.8706e-01,\n",
              "           -2.9529e-01, -2.7977e-01, -1.9097e-01, -3.9708e-01, -5.7893e-01,\n",
              "           -1.3890e-01,  1.1516e-01,  1.6709e-01, -5.6689e-01,  9.5089e-02],\n",
              "          [ 1.0854e-01,  7.3554e-02, -3.6750e-01,  4.1144e-01, -1.1953e-01,\n",
              "            1.8573e-01,  3.3334e-01, -4.4379e-02, -2.9302e-01, -5.9883e-03,\n",
              "            2.0871e-01, -1.6103e-01, -3.8515e-01, -1.4210e-01, -7.9402e-02,\n",
              "            8.8438e-02, -1.4678e-01,  1.4566e-01, -6.7724e-03, -1.1286e-01,\n",
              "           -1.7643e-01, -1.1608e-01, -3.2812e-02, -3.7309e-01, -1.3270e-01,\n",
              "            1.4351e-01, -1.2537e-01,  1.1051e-01,  9.1990e-02, -4.9283e-02,\n",
              "           -1.3755e-01,  2.5441e-01,  7.8921e-02, -2.0930e-01, -3.8418e-01,\n",
              "            4.1859e-02, -4.2404e-01,  2.1191e-01,  7.4438e-02, -2.2408e-02,\n",
              "           -7.5491e-02, -3.6166e-01, -8.1271e-02,  4.6062e-02, -1.3181e-01,\n",
              "            3.0232e-02, -2.9203e-01,  3.6198e-02,  2.6364e-01, -1.2841e-01,\n",
              "            1.0566e-01, -5.9188e-02,  3.7622e-01,  1.9881e-01, -2.4434e-01,\n",
              "           -2.6755e-01, -3.0916e-01, -3.6048e-01, -3.8916e-01, -3.8234e-01,\n",
              "           -2.3288e-01,  1.0323e-01,  9.6941e-02, -4.2510e-01,  5.9862e-02],\n",
              "          [ 1.9548e-01,  8.2042e-02, -3.4063e-01,  4.2742e-01, -7.6474e-02,\n",
              "            1.4629e-01,  3.2807e-01, -1.2743e-01, -3.3302e-01,  3.9257e-02,\n",
              "            1.8526e-01, -1.7315e-01, -4.4084e-01, -7.7868e-02, -3.2913e-02,\n",
              "            2.8490e-02, -1.0143e-01,  7.9976e-03, -9.7263e-02, -9.2076e-02,\n",
              "           -1.8021e-01, -5.3890e-02,  3.4849e-02, -3.9175e-01, -1.0661e-01,\n",
              "            1.5919e-01, -2.3884e-01,  7.7726e-02,  7.5014e-02,  3.4608e-02,\n",
              "           -1.1358e-01,  2.6674e-01,  1.2969e-01, -1.2123e-01, -3.2349e-01,\n",
              "            1.1327e-01, -4.2836e-01,  2.3368e-01,  2.9789e-02,  7.0261e-02,\n",
              "           -5.1672e-02, -3.3575e-01, -9.4441e-02,  6.9981e-02, -1.5597e-01,\n",
              "            9.0651e-02, -2.0300e-01,  1.2068e-01,  2.0977e-01, -1.7134e-01,\n",
              "            1.3510e-01, -5.9308e-02,  4.7639e-01,  2.5233e-01, -3.0560e-01,\n",
              "           -2.3118e-01, -2.2935e-01, -3.1752e-01, -3.6976e-01, -3.8083e-01,\n",
              "           -1.7211e-01,  1.0011e-01,  1.2852e-01, -4.8264e-01,  7.1967e-02]]],\n",
              "        grad_fn=<ViewBackward0>),\n",
              " tensor(4.0928, grad_fn=<NllLossBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "head1 = selfAttentionHead(16)"
      ],
      "metadata": {
        "id": "BoaNPfYD-fP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((batch_size,block_size,n_embd))    #(1,8,32)"
      ],
      "metadata": {
        "id": "l9_EvUAYA7p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_out = head1(input)"
      ],
      "metadata": {
        "id": "kN8XE7n_BUCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq9a9EB8BV8h",
        "outputId": "56da0b15-ce80-4cdb-d7df-4d47a6c7c243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT test"
      ],
      "metadata": {
        "id": "wgoEIf_pWKZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#hyperparameters\n",
        "block_size = 8\n",
        "batch_size = 32\n",
        "n_embd = 64\n",
        "num_heads = 4\n",
        "head_size = n_embd // num_heads\n",
        "eval_iter = 10000\n",
        "max_iter = 10000\n",
        "lr = 1e-3\n",
        "\n",
        "\n",
        "\n",
        "# #text read\n",
        "# with open('data/input.txt', 'r') as f:\n",
        "#     text = f.read()\n",
        "\n",
        "\n",
        "#get characters from input.txt\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "\n",
        "#encoding and decoding\n",
        "stoi = {s:i for i,s in enumerate(chars)}\n",
        "itos = {i:s for i,s in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "\n",
        "\n",
        "# encode text\n",
        "data = encode(text)\n",
        "\n",
        "# train / val split\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "\n",
        "\n",
        "# create mini batch\n",
        "def get_batch(split):\n",
        "\n",
        "    data = train_data if split=='train' else val_data\n",
        "\n",
        "    idx = torch.randint(len(data)-block_size , (block_size,))\n",
        "\n",
        "    x = torch.tensor([data[i:i+block_size] for i in idx])\n",
        "    y = torch.tensor([data[i+1:block_size+1+i] for i in idx])\n",
        "\n",
        "    return x,y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "\n",
        "class SaHead(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,head_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.key = nn.Linear(n_embd,head_size, bias = False)\n",
        "        self.query = nn.Linear(n_embd,head_size,bias = False)\n",
        "\n",
        "        self.value = nn.Linear(n_embd,head_size, bias = False)\n",
        "\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        B,T,C = x.shape\n",
        "\n",
        "        key = self.key(x)\n",
        "        query = self.query(x)\n",
        "\n",
        "        weight = query @ key.transpose(-2,-1) * C**-0.5\n",
        "        weight = weight.masked_fill(self.tril[:T,:T]==0,float('-inf'))\n",
        "        weight = F.softmax(weight,dim=-1)\n",
        "\n",
        "        value = self.value(x)\n",
        "\n",
        "        out = weight @ value\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHead(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads,head_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sa_heads = nn.ModuleList([SaHead(head_size) for i in range(num_heads)])\n",
        "        self.projection = nn.Linear(num_heads * head_size , n_embd)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = torch.cat([sa(x) for sa in self.sa_heads],dim = -1)\n",
        "\n",
        "        out = self.projection(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self,n_embd):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd,n_embd) # projection\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self,num_heads,n_embd):\n",
        "        super().__init__()\n",
        "\n",
        "        head_size = n_embd // num_heads\n",
        "\n",
        "        self.heads = MultiHead(num_heads,head_size)\n",
        "        self.mlp = MLP(n_embd)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embd)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        # added pre layerNorms\n",
        "        out = self.heads(self.layer_norm1(x)) + x  # residual conn\n",
        "        out = self.mlp(self.layer_norm2(out)) + out  # residual conn\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embd_table = nn.Embedding(vocab_size,n_embd)\n",
        "        self.pos_embd_table = nn.Embedding(block_size,n_embd)\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            Block(num_heads,n_embd),\n",
        "            Block(num_heads,n_embd),\n",
        "            Block(num_heads,n_embd)\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(n_embd,vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,input, targets = None):\n",
        "\n",
        "        B,T = input.shape\n",
        "\n",
        "        token_embd = self.embd_table(input)\n",
        "        pos_embd = self.pos_embd_table(torch.arange(T))\n",
        "\n",
        "        x = token_embd+pos_embd\n",
        "\n",
        "        x = self.block(x)\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B,T,C = logits.shape\n",
        "            loss = F.cross_entropy(logits.view(B*T,C),targets.view(-1))\n",
        "\n",
        "        return logits , loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        # create a PyTorch optimizer\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=lr)\n",
        "\n",
        "        for i in range(max_iter):\n",
        "\n",
        "            xb,yb = get_batch('train')\n",
        "\n",
        "            # evaluate model\n",
        "            logits , loss = self(xb,yb)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            if i% (max_iter/10) == 0:\n",
        "                print(f'{i}/{max_iter}  {loss}')\n",
        "            if i == max_iter-1:\n",
        "                print(f'{max_iter}/{max_iter}  {loss}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate(self,input,max_token):\n",
        "\n",
        "        for _ in range(max_token):\n",
        "            input_cond = input[:,-block_size:]\n",
        "            logits , loss = self(input_cond)\n",
        "            logits = logits[:,-1,:]\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_index = torch.multinomial(probs,1)\n",
        "\n",
        "            input = torch.cat((input,next_index),dim = 1)\n",
        "\n",
        "        return input\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "model = GPTModel()\n",
        "model.train()\n",
        "\n",
        "\n",
        "\n",
        "# genarate from the model\n",
        "context = torch.zeros((1,1),dtype=torch.long)\n",
        "print(decode(model.generate(context,max_token=100)[0].tolist()))"
      ],
      "metadata": {
        "id": "7NOM6mr9Blfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6086e32e-0e07-4b4b-d5ad-3e4b5cfc2789"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/10000  4.459923267364502\n",
            "1000/10000  2.1904923915863037\n",
            "2000/10000  2.2503855228424072\n",
            "3000/10000  2.071443796157837\n",
            "4000/10000  2.065601110458374\n",
            "5000/10000  1.9764474630355835\n",
            "6000/10000  2.150885581970215\n",
            "7000/10000  2.163971424102783\n",
            "8000/10000  2.1968228816986084\n",
            "9000/10000  1.843940258026123\n",
            "10000/10000  1.844292163848877\n",
            "\n",
            "Mence\n",
            "Buchils and straak scome.\n",
            "\n",
            "MENRY BTHARD:\n",
            "How, fittys', and your fidly, in beftend; wistreded, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1),dtype=torch.long)\n",
        "print(decode(model.generate(context,max_token=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaQdgGB1WN94",
        "outputId": "f5d702cf-d75e-4346-bf2b-bded8d45ad3c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Then thither presilme,\n",
            "Shalk; Monatons in the diss, hiner-ver bite,\n",
            "Master, inten that sene a centio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fRfevGZRXyPy"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}