{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaBckG5DL2cCDeFA49NxdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitha278/gpt-from-scratch/blob/main/GPT_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import random"
      ],
      "metadata": {
        "id": "tDPI-mQIHtht"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1ia6z4itw7WJWpnoTohURX6Lm-AnZmVZz\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "output = \"input.txt\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "vX2lDjnvIvll",
        "outputId": "865f6bad-c204-4513-d40c-d6ab4823add0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ia6z4itw7WJWpnoTohURX6Lm-AnZmVZz\n",
            "To: /content/input.txt\n",
            "100%|██████████| 1.12M/1.12M [00:00<00:00, 144MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nv2qQxTJYH0",
        "outputId": "3a658e65-c2f1-4785-fa05-dd3af8038e63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw2xR7QTKFvp",
        "outputId": "52e498e1-02d7-4486-8086-1fb201abc62a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {s:i for i,s in enumerate(chars)}\n",
        "itos = {i:s for i,s in enumerate(chars)}\n",
        "\n",
        "encode = lambda s : [stoi[ch] for ch in s]\n",
        "decode = lambda l : ''.join(itos[i] for i in l)\n",
        "\n",
        "print(encode(\"Hello world\"))\n",
        "print(decode(encode(\"Hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnqtaA5KG4X",
        "outputId": "b2ca908a-8603-45be-99ce-5ed6f0d40a54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
            "Hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text))\n",
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjyancDSRgIp",
        "outputId": "ce70313d-2233-4b96-837f-2e3055084005"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
              "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
              "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
              "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
              "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9* len(data))\n",
        "train = data[:n]\n",
        "val = data[n:]"
      ],
      "metadata": {
        "id": "gCCeKh6WUFYG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "\n",
        "x = train[:block_size]\n",
        "y = train[1:block_size+1]\n",
        "\n",
        "for i in range(block_size):\n",
        "  context = x[:i+1]\n",
        "  target = y[i]\n",
        "\n",
        "  print(f'{context} target:{target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F1f9l90VVvC",
        "outputId": "cc7697d0-53d6-46a8-99f1-f893b23c2aae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18]) target:47\n",
            "tensor([18, 47]) target:56\n",
            "tensor([18, 47, 56]) target:57\n",
            "tensor([18, 47, 56, 57]) target:58\n",
            "tensor([18, 47, 56, 57, 58]) target:1\n",
            "tensor([18, 47, 56, 57, 58,  1]) target:15\n",
            "tensor([18, 47, 56, 57, 58,  1, 15]) target:47\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47]) target:58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(100-block_size, (4,))\n",
        "ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0dSQLVFM4UQ",
        "outputId": "732682e9-b33d-4fcf-886f-960897157a58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([21, 38, 46, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(278)\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "\n",
        "def get_batch(split):\n",
        "\n",
        "  data = train if split=='train' else val\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:block_size+i] for i in ix])\n",
        "  y = torch.stack([data[i+1:block_size+i+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "\n",
        "xb,yb = get_batch('train')\n",
        "\n",
        "xb,yb"
      ],
      "metadata": {
        "id": "VUqDG0uBcN0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a53bf0-92b2-40a9-ce16-4842d287189f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[47, 57,  0, 42, 39, 59, 45, 46],\n",
              "         [40, 59, 58,  1, 40, 39, 57, 58],\n",
              "         [58, 53,  1, 46, 43, 56,  1, 57],\n",
              "         [50, 63,  0, 58, 39, 56, 56, 63]]),\n",
              " tensor([[57,  0, 42, 39, 59, 45, 46, 58],\n",
              "         [59, 58,  1, 40, 39, 57, 58, 39],\n",
              "         [53,  1, 46, 43, 56,  1, 57, 53],\n",
              "         [63,  0, 58, 39, 56, 56, 63,  1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram Language Model"
      ],
      "metadata": {
        "id": "-bdswUyciIta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(278)\n",
        "\n",
        "class BigramLM(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.token_emb_table = nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "\n",
        "  def __call__(self,idx , targets=None):\n",
        "\n",
        "    logits = self.token_emb_table(idx)    #shape: (b,t,c)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      loss = F.cross_entropy(logits.view(-1,vocab_size) , targets.view(-1))\n",
        "\n",
        "    return logits , loss\n",
        "\n",
        "\n",
        "  def generate(self,idx, max_new_tokens):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "      logits , loss = self(idx)\n",
        "\n",
        "      logits = logits[:,-1,:] #from all batch's last element's logits\n",
        "\n",
        "      probs = F.softmax(logits,dim=1)\n",
        "\n",
        "      ix = torch.multinomial(probs,num_samples=1)\n",
        "\n",
        "      idx = torch.cat((idx,ix), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "\n",
        "bigram = BigramLM(vocab_size)\n",
        "logits , loss = bigram(xb,yb)\n",
        "\n",
        "print(logits.shape,loss)\n",
        "\n",
        "\n",
        "\n",
        "idx= torch.zeros((1,1),dtype= torch.long)\n",
        "\n",
        "print(decode(bigram.generate(idx,max_new_tokens=100)[0].tolist()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcc2HxMHv5l",
        "outputId": "e9304cff-c5db-4374-850c-ef6e903956c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 65]) tensor(4.5468, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "hDkMQcyOQpP-rU-,VfVk:rXwxj Ug$$kNRxr.x'R3ULl!WC?fErPF'K'nybrlziq:IF:J.-YVN.jj$R-kDwR\n",
            "hWiDAg,rHH'!JzL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([i.shape for i in bigram.parameters()])   #token_emb_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok6jBOBXMMAK",
        "outputId": "72996378-d94c-4f52-d3e9-7232cf4ac366"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.Size([65, 65])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(bigram.parameters(),lr = 1e-3)"
      ],
      "metadata": {
        "id": "O-8ftb_0kxxQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "  xb,yb = get_batch('train')\n",
        "\n",
        "  logits , loss = bigram(xb,yb)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%10000 == 0:\n",
        "    print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z18XvwxBqk7J",
        "outputId": "bd5ce036-2f7c-4882-c03f-9f729f525c96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.7092204093933105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx= torch.zeros((1,1),dtype= torch.long)\n",
        "\n",
        "print(decode(bigram.generate(idx,max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCpboy-Osf_q",
        "outputId": "5fa2978f-94b4-4db3-bdaf-cfc50ff3dc73"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "hW. U EQ&KHb\n",
            "SKB3FKB&jq&p;JoYXMvlik:cusuILA:ivFrod3Y!\n",
            "K?$ne FsT liO't JCoAHpEqKLKm!mLD3fMWArtawnJICl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging past context"
      ],
      "metadata": {
        "id": "szy4_fxo83D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = get_batch('train')\n",
        "x[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie_2vD6R8hWy",
        "outputId": "9dcfb93a-b5d3-4637-b523-a86460782116"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[49,  1, 46, 47, 57,  1, 45, 56],\n",
              "        [ 1, 50, 47, 60, 43,  6,  0, 21],\n",
              "        [61, 56, 39, 54,  1, 53, 59, 56],\n",
              "        [46,  7,  7,  0,  0, 29, 33, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = bigram(x,y)\n",
        "B,T,C = xb.shape\n",
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McqmuoSMs8KP",
        "outputId": "1a197468-0078-4960-dd6c-4d05598644c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros(xb.shape)\n",
        "\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "\n",
        "    xprev = xb[b,:t+1]\n",
        "    xbow[b,t] = xprev.mean(0)"
      ],
      "metadata": {
        "id": "EvqNBUVY8_8g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging with matrix multiplication"
      ],
      "metadata": {
        "id": "9zE5JLMNJZQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg8 = torch.tensor([1/i for i in range(1,T+1)])\n",
        "avg8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc4zw8RI98ts",
        "outputId": "56381894-76f0-4347-e9c9-9b0abbfbaaa1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 0.5000, 0.3333, 0.2500, 0.2000, 0.1667, 0.1429, 0.1250])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg88 = (avg8*torch.ones(T,T)).T"
      ],
      "metadata": {
        "id": "PyD4iqGcG1X7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg88_tril = torch.tril(avg88)\n",
        "avg88_tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym0kyf3_I9E-",
        "outputId": "b84633ef-ed10-44f2-ecf9-89b71c036fc1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(T,T))\n",
        "a = a / a.sum(1,keepdim=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwvxD1pXLBl3",
        "outputId": "7e543fcc-1e88-449c-ba7d-75c207a54a57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow_mat = torch.zeros(xb.shape)\n",
        "\n",
        "for batch in range(B):\n",
        "  xbow_mat[batch] = a @ xb[batch]\n"
      ],
      "metadata": {
        "id": "EZ9CAWEwJJrm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2 = a @ xb"
      ],
      "metadata": {
        "id": "oLQwX-QFMVSs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow,xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkkmgcC3KYPL",
        "outputId": "713d6735-e35f-45ab-d51d-0b17e4553be2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary of averaging"
      ],
      "metadata": {
        "id": "lhh4vygKNBV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(T,T))\n",
        "a = a / a.sum(1,keepdim=True)\n",
        "\n",
        "xbow = a @ xb\n"
      ],
      "metadata": {
        "id": "R7-Q7Pe6M1g1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 3"
      ],
      "metadata": {
        "id": "tyz-62DQRov_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "\n",
        "wei = F.softmax(wei,dim = 1)\n",
        "\n",
        "xbow3 = wei @ xb\n",
        "(xbow3 == xbow2).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Z9p3OuRoWM",
        "outputId": "e8d63128-43c7-4648-e44a-a3a209c2aaf0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version 4 - Self attention"
      ],
      "metadata": {
        "id": "Wo7yxXGNun3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(278)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "\n",
        "head_size = 16\n",
        "\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "id": "opdWkZ9qsDqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mat mul high dimension"
      ],
      "metadata": {
        "id": "R0NiIdN7sSHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((2,4,8))\n",
        "b = torch.randn((2,4,4))\n",
        "b @ a"
      ],
      "metadata": {
        "id": "JRyGfr0qKbvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d04804-79cf-4e0b-e7f7-58951c8d57f5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-5.4058e-01,  1.0871e+00, -7.8677e-01, -8.3727e-01,  3.3524e+00,\n",
              "          -1.9426e+00, -1.3025e+00,  2.1948e+00],\n",
              "         [-2.1327e+00,  1.5168e-01, -8.0400e-01, -4.9993e-01,  3.1513e+00,\n",
              "           1.0746e-01, -5.0937e-01, -1.4033e-01],\n",
              "         [ 9.5632e-02, -8.7058e-02,  1.0464e+00,  8.6520e-02,  2.6935e+00,\n",
              "          -1.9146e+00,  1.7717e+00, -1.1312e+00],\n",
              "         [ 1.2874e+00,  3.5285e-01,  7.8090e-01, -1.8364e-01,  1.6885e+00,\n",
              "          -3.1999e+00,  2.0273e-01,  2.0840e+00]],\n",
              "\n",
              "        [[-3.8173e-01,  2.8735e+00, -1.7417e+00, -9.4410e-01,  3.1398e+00,\n",
              "           5.5690e-01,  2.9697e-01,  5.7675e-02],\n",
              "         [-1.9084e+00,  7.5241e-01,  1.3158e-01, -2.6899e+00, -3.2975e+00,\n",
              "           1.0975e+00, -2.9906e+00,  2.7211e+00],\n",
              "         [ 1.1772e+00,  8.2719e-01, -4.8063e-01, -3.9931e-01,  1.0886e-01,\n",
              "           1.2323e-01, -2.9363e-01, -2.4614e+00],\n",
              "         [ 1.5371e-01, -6.6360e-02,  4.6119e-02, -8.1225e-02, -3.0130e-01,\n",
              "          -1.2745e-03, -1.4839e-01, -2.9773e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xt,yt = get_batch('train')\n",
        "\n",
        "xt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAvm6jslBQR9",
        "outputId": "a81ffe72-6a8e-4839-abb0-96ed046f135c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embd = nn.Embedding(65,40)\n",
        "token_embd.weight.shape\n",
        "\n",
        "out = token_embd(xt)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0u7GD7pC5Uh",
        "outputId": "ccb1fce4-21a4-4d6a-9506-497d21b98e8f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm_head = nn.Linear(40,65)\n",
        "lm_head.weight.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9x51LPjDFAi",
        "outputId": "75afbfd6-1cd9-4106-eca5-4e76117f3cf8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm_head(out).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azupvkEMLg_l",
        "outputId": "00745162-4140-462a-a489-a19a3f3be4ff"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84zZf-riL2hH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}